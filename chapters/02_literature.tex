\chapter{Literature Review}
\label{chap:literature_review}

% focussed, concise
% supports the well-stated question
% identifies a gap
% reports and critiques current state of discourse
% critical
% adds value

Considering our objective of comparing articles on the same events to derive insightful usage of language, we are bringing together different research topics:

\begin{itemize}
    \item same events: it requires to have a method to understand what is contained in news articles (language representation), in order to find groups of relevant articles;
    \item comparing: this implies techniques to see how similar or different are, on the macro scale or also in the details (similarity computation, plagiarism, corroboration)
    \item usage of language: we need linguistic features (POS, sentiment, subjectivity, ...)
\end{itemize}

For this reason, in this chapter we first focus on works that analyse how documents are talking about the same details, using language representations, clustering and seeing which details are narrated by different sources.
The objective of this first group is to extract the common ground between different stories and highlight the pieces that are uniquely changed, added or removed by individual sources.

Then we present works that characterise documents with linguistic features that we aim to use for the second phase, that is \emph{understanding} the framing that the choices of the authors use. For this reason, we analyse a set of features that have appeared in similar works.


\section{Relationships between articles}

% Definition of relationship
There are different possible types of relationships between news articles, such as similarity (covering the same information), referencing (one is citing another one), and temporal proximity. They can be performed at the document level (e.g., the whole article is similar to another one) or at the sentence level (e.g., the same sentence is corroborated by a sentence in another article~\cite{bountouridis2018explaining}) or even at the paragraph level.
Since we are interested in finding articles discussing the same information, we focus on similarity relationships.
% Other relationships could add interesting features, such as the order of publication which would help to identify which of the articles might have taken inspiration from the other. For the time being, we focus on studying and understanding the role of similarity.

Here in this section, we start with approaches that deal with language representation, then moving to clustering methods and then finally approaches to plagiarism detection and analysis of how the information repeats in multiple documents.

\subsection{Language representation}

This group of methods tackles one question: \emph{What is contained in the text?}

Starting with very naive methods,
Bag of words, stopwords

TF-IDF: how relevant and unique words are\cite{jones1972statistical}

Entity Recognition and Linking, triplets extraction

Word embeddings

Language Models era~\cite{devlin2018bert,cer2018universal,yang2019xlnet}.
With the recent explosion of Deep Learning representation there emerged many of Language Model tools that can provide document representation, like BERT~\cite{devlin2018bert}, XLnet~\cite{yang2019xlnet}, or even more oriented towards the similarity task: Universal Sentence Encoder~\cite{cer2018universal}.
And all these models can be used directly without the need to train, thanks to pretrained models that perform already well out-of-the-box.

Main strength of Language models:
relate articles that talk about the same events, even if they use different linguistic surface, from articles that may use the same subset of words but talk about different events, it is a semantic matching more than a word-based matching. 

\subsection{Clustering}

LDA
methods mostly used are Latent Dirichlet Allocation (LDA) or document embedding.
% News aggregators and LDA topic: can provide article-level aggregation
LDA~\cite{blei2003latent} is the most used technique for topic modelling, as it allows the discovery of topics and to group articles accordingly using word distributions.

Cliques

Distance-based

Hierarchical Clustering

% Topic Detection and Tracking steps
% 0. flat clusters: TDT before 2003. Simple LDA clustering methods
% 1. hierarchical topics: TDT 2003 (hierarchy of topic --> event --> story)
% 2. dependencies: 2004 Napallati~\cite{nallapati2004event}. They introduce edges with two possible reasons: causality or only temporal ordering.

% News event structure evolution (keep short)
% Instead in the direction of the structure of news event, we have a succession of works that went more in details than just creating groups / flat clusters generated by LDA.
% First of all \emph{hierarchical} topic modelling~\cite{allan2003flexible} that defined a set of levels (from the broad concept of topic, to the narrow event that belongs to the topic, and then a specific story/anecdote).
% And then moved to study the dependencies between events~\cite{nallapati2004event} with causality and temporal ordering.
% This recently brought to approaches that are able to find the events belonging to a topic and link them creating a Event Evolution Graph~\cite{yang2009discovering,ansah2019graph} that can be visualised to give an idea of the dependency between the events detected.
%\todo[color=yellow]{The removed paragraph was about events hierarchy and dependency}
% ~\cite{ansah2019graph} that is able to generate a visual story timeline summarisation, connecting the main events; Event Maps~\cite{yang2009discovering}
% Or works that focus on the illustrative side and use the extracted story timeline summarisation~\cite{ansah2019graph}.

% Furthermore, \cite{cai2019temporal} also presents event maps (original baseline~\cite{yang2009discovering}). With also importance score on the nodes and edges. The event relationships can be temporal, content dependence and event dependence.

\subsection{Plagiarism, corroborations and omissions}

Bountouridis

Furthermore, there are works that not only link the articles at a document level, but also investigate in more detail the connections between sentences.
In one recent work~\cite{bountouridis2018explaining}, groups of similar articles are found, then broken down to pieces of information and analysed to find if these details are \emph{corroborated} (occurring in multiple documents) or \emph{omitted} (occurring in other documents of the same group, but not the current one). 
%is good for getting relationships between paragraphs and documents. Corroboration and omission
% \begin{added}
We aim to use this idea of applying similarity to both article-level and sentence-level, extending it even to the word-level. By doing so,
not only we might be able to recognise which sentences appear in multiple documents (with different degrees of similarity) but also we would be able to identify the specific words that have been changed.

However, this set of approaches are limited to bringing to the attention of the reader the linked information pieces with a measure of similarity, without characterising the differences. The reader would then need to evaluate the differences in the role of the sentence, the framing that it implies and how it compares with other sentences in terms of subjectivity.
Different documents may express the same set of details, but give them a different role (reporting an action, commenting, contextualising, doing a digression, identifying causes and consequences) and use different words that are semantically similar but may imply a different framing perspective.
For this reason, the next subsection presents a set of narrative linguistic signals that could provide us with the missing features.

Citation Networks

Edit distances

Time evolution? TODO find stuff

\section{Linguistic features}

\subsection{Natural Language Parsing}

grammar, POS, dependencies

\subsection{Subjectivity and sentiment}

loaded language

In addition to these characterisations, we can add other signals derived from studies on \emph{subjectivity}.
% and sentiment intensity.
% https://www.niemanlab.org/2019/05/u-s-journalism-really-has-become-more-subjective-and-personal-at-least-some-of-it/ "a blurring of the line between opinion and fact."
As found by recent research, in contemporary journalism the line between opinion and facts is blurring more and more~\cite{blake2019news}. For this reason, having signals of subjectivity on the document and paragraph-level would be very useful~\cite{liu2010sentiment}.
%Furthermore, subjectivity is closely related to sentiment, since sentiment analysis is about finding the value of opinion while subjectivity is about distinguishing if the text is having an opinion or just reporting factual events~\cite{liu2010sentiment}.
In this way, each article and each paragraph can be characterised with an indication of subjectivity.

\subsection{Argumentation mining}

\subsection{Narrative features}

\cite{zahid2019towards}

some research considers the \emph{structural role} of a sentence in the document (e.g., is it providing some background, the main event, an evaluation).
Different structural roles have been defined in the literature, such as 
%Different works define sets of structural roles: 
news schema~\cite{bell1991language}, which identifies hierarchical categories (e.g., action, reaction, consequence, context, history), narrative structure~\cite{bell2005news} (e.g., abstract, orientation, evaluation, complication, resolution), or linguistic signals~\cite{zahid2019towards,marcu2000theory}. 
%One recent study~\cite{zahid2019towards} proposed linguistic signals to be able to recognise the structural role.
%With such characterisations, we would be able to add to the sentence-level similarity links also their role in the different articles, to understand how their structure differs.
Such signals could be used to identify the differences between similar sentences with regards to their structural roles in the articles. 
% And this is an important feature because time structure and story structure are usually different~\cite{bell2005news}.

\subsection{Bias and Framing}

Framing and Linguistic frames (both on a single doc and on multiple docs, e.g. https://journals-sagepub-com.libezproxy.open.ac.uk/doi/pdf/10.1177/1077699015606670)

Mention AllSides\footnote{\url{https://www.allsides.com/story/admin}}

On the other hand, there is much literature on \emph{framing}, defined
as how a certain story is presented to shape mass opinion~\cite{goffman1974frame}, the addition to the underlying facts that reflects the sociocultural context
%(cultural, political, ...)
and acts as an underlying force to persuade the reader.
% Semantic frames~\cite{fillmore2006frame}
% News Media Frames~\cite{boydstun2014tracking} developed a schema of 15 cross-cutting framing dimensions, such as economics, morality, and politics, and
% dataset of human annotations~\cite{card2015media}
The work by~\cite{gamson1989media} describes a set of \emph{framing packages}, made of \emph{framing devices} (e.g., word choice, metaphors, catchphrases, 
%exemplars, depictions, descriptions, 
use of contrast, quantification) and \emph{reasoning devices} (e.g., problem definition, cause, consequence, solution, action%, moral evaluation
).
Additionally, the Frame Semantics Theory~\cite{fillmore2006frame} can be used to recognise lexical units of known frames.
By extracting these linguistic signals, we could represent the framing behind a certain piece of text, and there exist different approaches to extract the listed features~\cite{mandal2017overview,gao2018neural,asghar2016automatic,swayamdipta:17}.


\section{Gaps}

All these features have been used in previous research, but as mentioned above, they are mainly applied to single-article analysis. Extending this kind of analysis by taking into consideration the relationships both at the article level and the sentence level would bring a big contribution by providing contrastive signals that would not come up otherwise. 

% \input{chapters/text2story_background}