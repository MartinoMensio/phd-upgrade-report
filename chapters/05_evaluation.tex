\chapter{Evaluation}
\label{chap:evaluation}

\todo{merge evaluation plan with proposal?}

\section{RQ1 evaluation}

\section{RQ2 evaluation}

\subsection{RQ2.1 evaluation}
% {RQ2.1: How well does the framing analysis relate with the information available on affiliation, newsgroup and bias of the single outlets?} With different features available for news sources, we want to see if some of them are related to the amount and type of framing that occurs on their articles.

With RQ2.1 we ask how does the framing analysis relate with the information of the single outlets (affiliation, newsgroup, bias, ...).

% requirement: data on news outlets
This question can be answered by pulling together information about news outlets.

- MBFC: political bias and factuality

- newsgroup: search info

- Others?

% how to answer RQ?
And once this information is available, we can aggregate a set of framing features (to be defined!!!) by the source of the articles.

With these two groups of information, we can study their correlation.

% possible outcomes
What a correlation analysis may say? For example that sources heavily biased (score on the source) tend to perform omissions or use loaded language.


% significance

\subsection{RQ2.2 evaluation}

% {RQ2.2: To what extent can we identify cascades of information using temporal information?} We aim at extracting temporised chains that track details across news sources, from where they are seen the first time and how they evolve through time and sources. How would this interact with rephrasing and other techniques that aim to avoid being spotted as plagiarism? (Linguistic variations vs semantics). And is temporal metadata reliable? (silent edits...)

Instead RQ2.2 questions the utility of temporal information. 
